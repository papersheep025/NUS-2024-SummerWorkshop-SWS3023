{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x-men</th>\n",
       "      <th>antman</th>\n",
       "      <th>frozen</th>\n",
       "      <th>cinderalla</th>\n",
       "      <th>annabelle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alice</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bob</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x-men  antman  frozen  cinderalla  annabelle\n",
       "alice    NaN     NaN     5.0           5        2.0\n",
       "bob      4.0     5.0     NaN           1        NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utility_matrix = pd.DataFrame([[np.nan, np.nan, 5, 5, 2],\n",
    "                               [4, 5, np.nan, 1, np.nan]], \n",
    "                    columns = [\"x-men\", \"antman\", \"frozen\", \"cinderalla\", \"annabelle\"],\n",
    "                    index = [\"alice\", \"bob\"])\n",
    "utility_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x-men         NaN\n",
       "antman        NaN\n",
       "frozen        5.0\n",
       "cinderalla    5.0\n",
       "annabelle     2.0\n",
       "Name: alice, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_rating = utility_matrix.loc[\"alice\"]\n",
    "alice_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x-men         4.0\n",
       "antman        5.0\n",
       "frozen        NaN\n",
       "cinderalla    1.0\n",
       "annabelle     NaN\n",
       "Name: bob, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_rating = utility_matrix.loc[\"bob\"]\n",
    "bob_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nansum((alice_rating - bob_rating) ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 5., 5., 2.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_rating_filled_zero = np.nan_to_num(alice_rating)\n",
    "alice_rating_filled_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 5., 0., 1., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_rating_filled_zero = np.nan_to_num(bob_rating)\n",
    "bob_rating_filled_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.3484692283495345\n",
      "7.3484692283495345\n",
      "6.48074069840786\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(alice_rating_filled_zero ** 2) ** 0.5)\n",
    "\n",
    "#to find the magnitude we can use np.linalg.norm()\n",
    "magnitude_alice = np.linalg.norm(alice_rating_filled_zero)\n",
    "print(magnitude_alice)\n",
    "\n",
    "magnitude_bob = np.linalg.norm(bob_rating_filled_zero)\n",
    "print(magnitude_bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10499013139145201"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cosine similarity is the dot product / product of the 2 magnitudes\n",
    "np.dot(alice_rating_filled_zero, bob_rating_filled_zero) / (magnitude_alice * magnitude_bob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson's Correlation Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at https://stats.stackexchange.com/questions/262925/is-there-a-serious-problem-with-dropping-observations-with-missing-values-when-c for reason why we should normalize the ratings by the mean of all ratings for each item (rather than just mean of the common items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_rating_mean = np.mean(alice_rating)\n",
    "alice_rating_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3333333333333335"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_rating_mean = np.mean(bob_rating)\n",
    "bob_rating_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x-men         NaN\n",
       "antman        NaN\n",
       "frozen        1.0\n",
       "cinderalla    1.0\n",
       "annabelle    -2.0\n",
       "Name: alice, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_normalized_rating = (alice_rating - alice_rating_mean)\n",
    "alice_normalized_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x-men         False\n",
       "antman        False\n",
       "frozen         True\n",
       "cinderalla     True\n",
       "annabelle      True\n",
       "Name: alice, dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find which item is rated by alice\n",
    "~np.isnan(alice_normalized_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x-men         0.666667\n",
       "antman        1.666667\n",
       "frozen             NaN\n",
       "cinderalla   -2.333333\n",
       "annabelle          NaN\n",
       "Name: bob, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_normalized_rating = (bob_rating - bob_rating_mean)\n",
    "bob_normalized_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x-men          True\n",
       "antman         True\n",
       "frozen        False\n",
       "cinderalla     True\n",
       "annabelle     False\n",
       "Name: bob, dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find which item is rated by bob\n",
    "~np.isnan(bob_normalized_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x-men         False\n",
       "antman        False\n",
       "frozen        False\n",
       "cinderalla     True\n",
       "annabelle     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_rated_items = ~np.isnan(alice_normalized_rating) & ~np.isnan(bob_normalized_rating)\n",
    "common_rated_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_normalized_common_rating = alice_normalized_rating.values[common_rated_items.values]\n",
    "alice_normalized_common_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magnitude_alice_common = np.linalg.norm(alice_normalized_common_rating)\n",
    "magnitude_alice_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.33333333])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_normalized_common_rating = bob_normalized_rating.values[common_rated_items.values]\n",
    "bob_normalized_common_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3333333333333335"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magnitude_bob_common = np.linalg.norm(bob_normalized_common_rating)\n",
    "magnitude_bob_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.3333333333333335"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(alice_normalized_common_rating, bob_normalized_common_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(alice_normalized_common_rating, bob_normalized_common_rating) / ( magnitude_alice_common * magnitude_bob_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
